{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764c8187-cbd4-4876-8265-8b9078e7fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import pycocotools.coco\n",
    "import pycocowriter.coco2yolo\n",
    "import requests\n",
    "import sys\n",
    "from hierarchical_yolo.hierarchical_detection import *\n",
    "from hierarchical_yolo.deep7_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c7293-4207-48ba-a2ef-298475fbfb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb177bc-b6cf-432e-b4f5-0aae2c5cb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "deep7 categories:\n",
    "\n",
    "  0: Kalekale\n",
    "  1: Opakapaka\n",
    "  2: \"Hapu\\u02BBupu\\u02BBu\"\n",
    "  3: Gindai\n",
    "  4: Other or Can't Tell\n",
    "  5: Ehu\n",
    "  6: Lehi\n",
    "  7: Onaga\n",
    "  8: Snapper\n",
    "  9: Grouper\n",
    "  10: Object\n",
    "'''\n",
    "\n",
    "deep7_hierarchy = {\n",
    "    0: 8,\n",
    "    1: 8,\n",
    "    2: 9,\n",
    "    3: 8,\n",
    "    5: 8,\n",
    "    6: 8,\n",
    "    7: 8,\n",
    "    4: 10,\n",
    "    8: 10,\n",
    "    9: 10\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb97d80a-f6f2-4393-8478-020a2f06ee1f",
   "metadata": {},
   "source": [
    "'''\n",
    "deep7 categories:\n",
    "\n",
    "  0: Kalekale\n",
    "  1: Opakapaka\n",
    "  2: \"Hapu\\u02BBupu\\u02BBu\"\n",
    "  3: Gindai\n",
    "  4: Fish\n",
    "  5: Ehu\n",
    "  6: Lehi\n",
    "  7: Onaga\n",
    "'''\n",
    "\n",
    "deep7_hierarchy = {\n",
    "    4: set((0,1,2,3,5,6,7))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b8bb38-c441-4170-9995-631dc9e1fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "deep7 categories:\n",
    "\n",
    "  0: Kalekale\n",
    "  1: Opakapaka\n",
    "  2: \"Hapu\\u02BBupu\\u02BBu\"\n",
    "  3: Gindai\n",
    "  4: Fish\n",
    "  5: Ehu\n",
    "  6: Lehi\n",
    "  7: Onaga\n",
    "'''\n",
    "\n",
    "deep7_hierarchy = {\n",
    "    0: 4,\n",
    "    1: 4,\n",
    "    2: 4,\n",
    "    3: 4,\n",
    "    5: 4,\n",
    "    6: 4,\n",
    "    7: 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0640363b-0060-4aa9-a0ef-582a50cf6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"/home/noaa_brown/.config/Ultralytics/settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"/home/noaa_brown/datasets\",\n",
      "  \"weights_dir\": \"/home/noaa_brown/hierarchical_yolo/weights\",\n",
      "  \"runs_dir\": \"/home/noaa_brown/hierarchical_yolo/runs\",\n",
      "  \"uuid\": \"2768c477e7938b5779aff75aed83103f60cf5680dbe7372dfa0b27c233b7d105\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": true,\n",
      "  \"wandb\": false,\n",
      "  \"vscode_msg\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "# View all settings\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0aec1b9-f9d8-444e-872d-e4325536c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "devices = list(range(torch.cuda.device_count()))\n",
    "for i in devices:\n",
    "    print(torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae883218-3991-4f85-87f5-8f0135149418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9dd415-94a5-4404-8e63-3338af4b0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../data'\n",
    "UPLOAD_URL = 'https://storage.googleapis.com/nmfs_odp_hq/nodd_tools/datasets/oceaneyes/annotation_number_balanced_sample/annotations.json'\n",
    "DOWNLOAD_PATH = os.path.join(DATA, 'download')\n",
    "COCO_PATH = os.path.join(DOWNLOAD_PATH, 'annotations.json')\n",
    "YOLO_PATH = os.path.join(DOWNLOAD_PATH, 'yolo_training_data')\n",
    "IMAGES_PATH = os.path.join(YOLO_PATH, 'annotations', 'images')\n",
    "os.makedirs(YOLO_PATH, exist_ok=True)\n",
    "os.makedirs(DOWNLOAD_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395cda29-0475-48c9-915f-89e3de1b86b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "uploaded_coco_file = requests.get(UPLOAD_URL)\n",
    "with open(COCO_PATH, 'wb') as f:\n",
    "    f.write(uploaded_coco_file.content)\n",
    "    coco = pycocotools.coco.COCO(COCO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56d22fa-1bbb-4b68-a967-39230932b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2024\n",
      "version: 0.1\n",
      "description: https://www.zooniverse.org/projects/benjamin-dot-richards/oceaneyes/about/research\n",
      "contributor: None\n",
      "url: None\n",
      "date_created: 2025-02-06T20:56:54.886937+00:00\n"
     ]
    }
   ],
   "source": [
    "coco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f158b5e3-b424-42df-b090-adf0841d1516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/noaa_brown/hierarchical_yolo/data/download/annotations.json: 100%|██████████| 200/200 [00:00<00:00, 1072.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/noaa_brown/hierarchical_yolo/notebooks/coco_converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "downloaded 0/200 images (t=0.0s)\n",
      "downloaded 1/200 images (t=0.0s)\n",
      "downloaded 2/200 images (t=0.0s)\n",
      "downloaded 3/200 images (t=0.0s)\n",
      "downloaded 4/200 images (t=0.0s)\n",
      "downloaded 5/200 images (t=0.0s)\n",
      "downloaded 6/200 images (t=0.0s)\n",
      "downloaded 7/200 images (t=0.0s)\n",
      "downloaded 8/200 images (t=0.0s)\n",
      "downloaded 9/200 images (t=0.0s)\n",
      "downloaded 10/200 images (t=0.0s)\n",
      "downloaded 11/200 images (t=0.0s)\n",
      "downloaded 12/200 images (t=0.0s)\n",
      "downloaded 13/200 images (t=0.0s)\n",
      "downloaded 14/200 images (t=0.0s)\n",
      "downloaded 15/200 images (t=0.0s)\n",
      "downloaded 16/200 images (t=0.0s)\n",
      "downloaded 17/200 images (t=0.0s)\n",
      "downloaded 18/200 images (t=0.0s)\n",
      "downloaded 19/200 images (t=0.0s)\n",
      "downloaded 20/200 images (t=0.0s)\n",
      "downloaded 21/200 images (t=0.0s)\n",
      "downloaded 22/200 images (t=0.0s)\n",
      "downloaded 23/200 images (t=0.0s)\n",
      "downloaded 24/200 images (t=0.0s)\n",
      "downloaded 25/200 images (t=0.0s)\n",
      "downloaded 26/200 images (t=0.0s)\n",
      "downloaded 27/200 images (t=0.0s)\n",
      "downloaded 28/200 images (t=0.0s)\n",
      "downloaded 29/200 images (t=0.0s)\n",
      "downloaded 30/200 images (t=0.0s)\n",
      "downloaded 31/200 images (t=0.0s)\n",
      "downloaded 32/200 images (t=0.0s)\n",
      "downloaded 33/200 images (t=0.0s)\n",
      "downloaded 34/200 images (t=0.0s)\n",
      "downloaded 35/200 images (t=0.0s)\n",
      "downloaded 36/200 images (t=0.0s)\n",
      "downloaded 37/200 images (t=0.0s)\n",
      "downloaded 38/200 images (t=0.0s)\n",
      "downloaded 39/200 images (t=0.0s)\n",
      "downloaded 40/200 images (t=0.0s)\n",
      "downloaded 41/200 images (t=0.0s)\n",
      "downloaded 42/200 images (t=0.0s)\n",
      "downloaded 43/200 images (t=0.0s)\n",
      "downloaded 44/200 images (t=0.0s)\n",
      "downloaded 45/200 images (t=0.0s)\n",
      "downloaded 46/200 images (t=0.0s)\n",
      "downloaded 47/200 images (t=0.0s)\n",
      "downloaded 48/200 images (t=0.0s)\n",
      "downloaded 49/200 images (t=0.0s)\n",
      "downloaded 50/200 images (t=0.0s)\n",
      "downloaded 51/200 images (t=0.0s)\n",
      "downloaded 52/200 images (t=0.0s)\n",
      "downloaded 53/200 images (t=0.0s)\n",
      "downloaded 54/200 images (t=0.0s)\n",
      "downloaded 55/200 images (t=0.0s)\n",
      "downloaded 56/200 images (t=0.0s)\n",
      "downloaded 57/200 images (t=0.0s)\n",
      "downloaded 58/200 images (t=0.0s)\n",
      "downloaded 59/200 images (t=0.0s)\n",
      "downloaded 60/200 images (t=0.0s)\n",
      "downloaded 61/200 images (t=0.0s)\n",
      "downloaded 62/200 images (t=0.0s)\n",
      "downloaded 63/200 images (t=0.0s)\n",
      "downloaded 64/200 images (t=0.0s)\n",
      "downloaded 65/200 images (t=0.0s)\n",
      "downloaded 66/200 images (t=0.0s)\n",
      "downloaded 67/200 images (t=0.0s)\n",
      "downloaded 68/200 images (t=0.0s)\n",
      "downloaded 69/200 images (t=0.0s)\n",
      "downloaded 70/200 images (t=0.0s)\n",
      "downloaded 71/200 images (t=0.0s)\n",
      "downloaded 72/200 images (t=0.0s)\n",
      "downloaded 73/200 images (t=0.0s)\n",
      "downloaded 74/200 images (t=0.0s)\n",
      "downloaded 75/200 images (t=0.0s)\n",
      "downloaded 76/200 images (t=0.0s)\n",
      "downloaded 77/200 images (t=0.0s)\n",
      "downloaded 78/200 images (t=0.0s)\n",
      "downloaded 79/200 images (t=0.0s)\n",
      "downloaded 80/200 images (t=0.0s)\n",
      "downloaded 81/200 images (t=0.0s)\n",
      "downloaded 82/200 images (t=0.0s)\n",
      "downloaded 83/200 images (t=0.0s)\n",
      "downloaded 84/200 images (t=0.0s)\n",
      "downloaded 85/200 images (t=0.0s)\n",
      "downloaded 86/200 images (t=0.0s)\n",
      "downloaded 87/200 images (t=0.0s)\n",
      "downloaded 88/200 images (t=0.0s)\n",
      "downloaded 89/200 images (t=0.0s)\n",
      "downloaded 90/200 images (t=0.0s)\n",
      "downloaded 91/200 images (t=0.0s)\n",
      "downloaded 92/200 images (t=0.0s)\n",
      "downloaded 93/200 images (t=0.0s)\n",
      "downloaded 94/200 images (t=0.0s)\n",
      "downloaded 95/200 images (t=0.0s)\n",
      "downloaded 96/200 images (t=0.0s)\n",
      "downloaded 97/200 images (t=0.0s)\n",
      "downloaded 98/200 images (t=0.0s)\n",
      "downloaded 99/200 images (t=0.0s)\n",
      "downloaded 100/200 images (t=0.0s)\n",
      "downloaded 101/200 images (t=0.0s)\n",
      "downloaded 102/200 images (t=0.0s)\n",
      "downloaded 103/200 images (t=0.0s)\n",
      "downloaded 104/200 images (t=0.0s)\n",
      "downloaded 105/200 images (t=0.0s)\n",
      "downloaded 106/200 images (t=0.0s)\n",
      "downloaded 107/200 images (t=0.0s)\n",
      "downloaded 108/200 images (t=0.0s)\n",
      "downloaded 109/200 images (t=0.0s)\n",
      "downloaded 110/200 images (t=0.0s)\n",
      "downloaded 111/200 images (t=0.0s)\n",
      "downloaded 112/200 images (t=0.0s)\n",
      "downloaded 113/200 images (t=0.0s)\n",
      "downloaded 114/200 images (t=0.0s)\n",
      "downloaded 115/200 images (t=0.0s)\n",
      "downloaded 116/200 images (t=0.0s)\n",
      "downloaded 117/200 images (t=0.0s)\n",
      "downloaded 118/200 images (t=0.0s)\n",
      "downloaded 119/200 images (t=0.0s)\n",
      "downloaded 120/200 images (t=0.0s)\n",
      "downloaded 121/200 images (t=0.0s)\n",
      "downloaded 122/200 images (t=0.0s)\n",
      "downloaded 123/200 images (t=0.0s)\n",
      "downloaded 124/200 images (t=0.0s)\n",
      "downloaded 125/200 images (t=0.0s)\n",
      "downloaded 126/200 images (t=0.0s)\n",
      "downloaded 127/200 images (t=0.0s)\n",
      "downloaded 128/200 images (t=0.0s)\n",
      "downloaded 129/200 images (t=0.0s)\n",
      "downloaded 130/200 images (t=0.0s)\n",
      "downloaded 131/200 images (t=0.0s)\n",
      "downloaded 132/200 images (t=0.0s)\n",
      "downloaded 133/200 images (t=0.0s)\n",
      "downloaded 134/200 images (t=0.0s)\n",
      "downloaded 135/200 images (t=0.0s)\n",
      "downloaded 136/200 images (t=0.0s)\n",
      "downloaded 137/200 images (t=0.0s)\n",
      "downloaded 138/200 images (t=0.0s)\n",
      "downloaded 139/200 images (t=0.0s)\n",
      "downloaded 140/200 images (t=0.0s)\n",
      "downloaded 141/200 images (t=0.0s)\n",
      "downloaded 142/200 images (t=0.0s)\n",
      "downloaded 143/200 images (t=0.0s)\n",
      "downloaded 144/200 images (t=0.0s)\n",
      "downloaded 145/200 images (t=0.0s)\n",
      "downloaded 146/200 images (t=0.0s)\n",
      "downloaded 147/200 images (t=0.0s)\n",
      "downloaded 148/200 images (t=0.0s)\n",
      "downloaded 149/200 images (t=0.0s)\n",
      "downloaded 150/200 images (t=0.0s)\n",
      "downloaded 151/200 images (t=0.0s)\n",
      "downloaded 152/200 images (t=0.0s)\n",
      "downloaded 153/200 images (t=0.0s)\n",
      "downloaded 154/200 images (t=0.0s)\n",
      "downloaded 155/200 images (t=0.0s)\n",
      "downloaded 156/200 images (t=0.0s)\n",
      "downloaded 157/200 images (t=0.0s)\n",
      "downloaded 158/200 images (t=0.0s)\n",
      "downloaded 159/200 images (t=0.0s)\n",
      "downloaded 160/200 images (t=0.0s)\n",
      "downloaded 161/200 images (t=0.0s)\n",
      "downloaded 162/200 images (t=0.0s)\n",
      "downloaded 163/200 images (t=0.0s)\n",
      "downloaded 164/200 images (t=0.0s)\n",
      "downloaded 165/200 images (t=0.0s)\n",
      "downloaded 166/200 images (t=0.0s)\n",
      "downloaded 167/200 images (t=0.0s)\n",
      "downloaded 168/200 images (t=0.0s)\n",
      "downloaded 169/200 images (t=0.0s)\n",
      "downloaded 170/200 images (t=0.0s)\n",
      "downloaded 171/200 images (t=0.0s)\n",
      "downloaded 172/200 images (t=0.0s)\n",
      "downloaded 173/200 images (t=0.0s)\n",
      "downloaded 174/200 images (t=0.0s)\n",
      "downloaded 175/200 images (t=0.0s)\n",
      "downloaded 176/200 images (t=0.0s)\n",
      "downloaded 177/200 images (t=0.0s)\n",
      "downloaded 178/200 images (t=0.0s)\n",
      "downloaded 179/200 images (t=0.0s)\n",
      "downloaded 180/200 images (t=0.0s)\n",
      "downloaded 181/200 images (t=0.0s)\n",
      "downloaded 182/200 images (t=0.0s)\n",
      "downloaded 183/200 images (t=0.0s)\n",
      "downloaded 184/200 images (t=0.0s)\n",
      "downloaded 185/200 images (t=0.0s)\n",
      "downloaded 186/200 images (t=0.0s)\n",
      "downloaded 187/200 images (t=0.0s)\n",
      "downloaded 188/200 images (t=0.0s)\n",
      "downloaded 189/200 images (t=0.0s)\n",
      "downloaded 190/200 images (t=0.0s)\n",
      "downloaded 191/200 images (t=0.0s)\n",
      "downloaded 192/200 images (t=0.0s)\n",
      "downloaded 193/200 images (t=0.0s)\n",
      "downloaded 194/200 images (t=0.0s)\n",
      "downloaded 195/200 images (t=0.0s)\n",
      "downloaded 196/200 images (t=0.0s)\n",
      "downloaded 197/200 images (t=0.0s)\n",
      "downloaded 198/200 images (t=0.0s)\n",
      "downloaded 199/200 images (t=0.0s)\n"
     ]
    }
   ],
   "source": [
    "pycocowriter.coco2yolo.coco2yolo(DOWNLOAD_PATH, YOLO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db4e6a-4077-4fc6-ab82-5f9999738574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e415ec-f0c2-48e2-8633-867199e3f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: the yolov8.yaml model file downloaded from Ultralytics needs manual editing for the number of classes\n",
    "YOLO_YAML = os.path.join(DATA, 'yolov8.yaml')\n",
    "YOLO_BASE_MODEL = os.path.join(DATA, 'yolov8n.pt')\n",
    "YOLO_TRAIN_YAML = os.path.join(YOLO_PATH, 'train.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3438182-1a11-466e-8fac-c30c276de0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d1985-c845-4018-8328-daf8502727fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7f6069-bf43-40e1-ab11-450c5425e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "Transferred 319/355 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(YOLO_YAML).load(YOLO_BASE_MODEL)  # build a new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3c7e87-6e3f-466c-b4fe-4065202b6970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.111 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.104 🚀 Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:1 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:2 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:3 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:4 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:5 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:6 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=../data/yolov8.yaml, data=../data/download/yolo_training_data/train.yaml, epochs=5, time=None, patience=100, batch=7, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1, 2, 3, 4, 5, 6], workers=8, project=None, name=train72, exist_ok=False, pretrained=../data/yolov8n.pt, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/noaa_brown/hierarchical_yolo/runs/detect/train72\n",
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "YOLOv8 summary: 129 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /home/noaa_brown/hierarchical_yolo/.venv/bin/python3 -m torch.distributed.run --nproc_per_node 7 --master_port 60379 /home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\n",
      "Error decoding JSON from /home/noaa_brown/.config/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Error decoding JSON from /home/noaa_brown/.config/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Error decoding JSON from /home/noaa_brown/.config/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Error decoding JSON from /home/noaa_brown/.config/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Ultralytics 8.3.104 🚀 Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:1 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:2 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:3 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:4 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:5 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "                                                       CUDA:6 (NVIDIA GeForce GTX 1080 Ti, 11165MiB)\n",
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/noaa_brown/hierarchical_yolo/data/download/yolo_training_data/annotations/labels.cache... 200 images, 0 backgrounds, 1 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/noaa_brown/hierarchical_yolo/data/download/yolo_training_data/annotations/images/20190913_201709_20190913.203153.002.010131.jpg: ignoring corrupt image/label: negative label values [-0.00068681]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/noaa_brown/hierarchical_yolo/data/download/yolo_training_data/annotations/labels.cache... 200 images, 0 backgrounds, 1 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/noaa_brown/hierarchical_yolo/data/download/yolo_training_data/annotations/images/20190913_201709_20190913.203153.002.010131.jpg: ignoring corrupt image/label: negative label values [-0.00068681]\n",
      "Plotting labels to /home/noaa_brown/hierarchical_yolo/runs/detect/train72/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0004921875), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(1b7bfc948e84446ea170b8317f657aa6) to /home/noaa_brown/hierarchical_yolo/runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri /home/noaa_brown/hierarchical_yolo/runs/mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 14 dataloader workers\n",
      "Logging results to \u001b[1m/home/noaa_brown/hierarchical_yolo/runs/detect/train72\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "torch.Size([1, 8400, 8])\n",
      "torch.Size([1, 8400])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "torch.Size([8, 2])\n",
      "torch.Size([1, 8400, 2])\n",
      "torch.Size([1, 8400, 2])\n",
      "[torch.Size([1, 8400, 2]), torch.Size([1, 8400, 2]), torch.Size([1, 8400, 2])]\n",
      "torch.Size([1, 8400, 2])\n",
      "torch.Size([1, 8400, 2])\n",
      "torch.Size([1, 8400, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank0]:     results = trainer.train()\n",
      "[rank0]:               ^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank0]:     self._do_train(world_size)\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank0]:     loss, self.loss_items = self.model(batch)\n",
      "[rank0]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank0]:     return self.loss(x, *args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank0]:     return self.criterion(preds, batch)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank0]:     raise Exception('done')\n",
      "[rank0]: Exception: done\n",
      "[rank6]: Traceback (most recent call last):\n",
      "[rank6]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank6]:     results = trainer.train()\n",
      "[rank6]:               ^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank6]:     self._do_train(world_size)\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank6]:     loss, self.loss_items = self.model(batch)\n",
      "[rank6]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank6]:     return self._call_impl(*args, **kwargs)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank6]:     return forward_call(*args, **kwargs)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank6]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank6]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank6]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank6]:     return self._call_impl(*args, **kwargs)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank6]:     return forward_call(*args, **kwargs)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank6]:     return self.loss(x, *args, **kwargs)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank6]:     return self.criterion(preds, batch)\n",
      "[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank6]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank6]:     raise Exception('done')\n",
      "[rank6]: Exception: done\n",
      "[rank5]: Traceback (most recent call last):\n",
      "[rank5]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank5]:     results = trainer.train()\n",
      "[rank5]:               ^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank5]:     self._do_train(world_size)\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank5]:     loss, self.loss_items = self.model(batch)\n",
      "[rank5]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank5]:     return self._call_impl(*args, **kwargs)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank5]:     return forward_call(*args, **kwargs)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank5]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank5]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank5]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank5]:     return self._call_impl(*args, **kwargs)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank5]:     return forward_call(*args, **kwargs)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank5]:     return self.loss(x, *args, **kwargs)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank5]:     return self.criterion(preds, batch)\n",
      "[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank5]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank5]:     raise Exception('done')\n",
      "[rank5]: Exception: done\n",
      "[rank4]: Traceback (most recent call last):\n",
      "[rank4]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank4]:     results = trainer.train()\n",
      "[rank4]:               ^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank4]:     self._do_train(world_size)\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank4]:     loss, self.loss_items = self.model(batch)\n",
      "[rank4]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank4]:     return self._call_impl(*args, **kwargs)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank4]:     return forward_call(*args, **kwargs)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank4]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank4]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank4]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank4]:     return self._call_impl(*args, **kwargs)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank4]:     return forward_call(*args, **kwargs)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank4]:     return self.loss(x, *args, **kwargs)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank4]:     return self.criterion(preds, batch)\n",
      "[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank4]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank4]:     raise Exception('done')\n",
      "[rank4]: Exception: done\n",
      "[rank3]: Traceback (most recent call last):\n",
      "[rank3]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank3]:     results = trainer.train()\n",
      "[rank3]:               ^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank3]:     self._do_train(world_size)\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank3]:     loss, self.loss_items = self.model(batch)\n",
      "[rank3]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank3]:     return self._call_impl(*args, **kwargs)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank3]:     return forward_call(*args, **kwargs)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank3]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank3]:     return self._call_impl(*args, **kwargs)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank3]:     return forward_call(*args, **kwargs)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank3]:     return self.loss(x, *args, **kwargs)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank3]:     return self.criterion(preds, batch)\n",
      "[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank3]:     raise Exception('done')\n",
      "[rank3]: Exception: done\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank2]:     results = trainer.train()\n",
      "[rank2]:               ^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank2]:     self._do_train(world_size)\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank2]:     loss, self.loss_items = self.model(batch)\n",
      "[rank2]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank2]:     return self._call_impl(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank2]:     return forward_call(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank2]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank2]:     return self._call_impl(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank2]:     return forward_call(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank2]:     return self.loss(x, *args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank2]:     return self.criterion(preds, batch)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank2]:     raise Exception('done')\n",
      "[rank2]: Exception: done\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py\", line 13, in <module>\n",
      "[rank1]:     results = trainer.train()\n",
      "[rank1]:               ^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "[rank1]:     self._do_train(world_size)\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n",
      "[rank1]:     loss, self.loss_items = self.model(batch)\n",
      "[rank1]:                             ^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank1]:     return self._call_impl(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank1]:     return forward_call(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank1]:     return self._call_impl(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank1]:     return forward_call(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 119, in forward\n",
      "[rank1]:     return self.loss(x, *args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py\", line 299, in loss\n",
      "[rank1]:     return self.criterion(preds, batch)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/noaa_brown/hierarchical_yolo/hierarchical_yolo/hierarchical_detection.py\", line 127, in __call__\n",
      "[rank1]:     raise Exception('done')\n",
      "[rank1]: Exception: done\n",
      "W0418 18:45:42.990000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138981 closing signal SIGTERM\n",
      "W0418 18:45:42.991000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138982 closing signal SIGTERM\n",
      "W0418 18:45:42.992000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138983 closing signal SIGTERM\n",
      "W0418 18:45:42.993000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138984 closing signal SIGTERM\n",
      "W0418 18:45:42.994000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138985 closing signal SIGTERM\n",
      "W0418 18:45:42.995000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 138987 closing signal SIGTERM\n",
      "E0418 18:45:43.311000 138978 .venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 5 (pid: 138986) of binary: /home/noaa_brown/hierarchical_yolo/.venv/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/run.py\", line 922, in <module>\n",
      "    main()\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/run.py\", line 918, in main\n",
      "    run(args)\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/noaa_brown/hierarchical_yolo/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-04-18_18:45:42\n",
      "  host      : viame.ceoas.oregonstate.edu\n",
      "  rank      : 5 (local_rank: 5)\n",
      "  exitcode  : 1 (pid: 138986)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/home/noaa_brown/hierarchical_yolo/.venv/bin/python3', '-m', 'torch.distributed.run', '--nproc_per_node', '7', '--master_port', '60379', '/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mYOLO_TRAIN_YAML\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDeep7HierarchicalDetectionTrainer\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:791\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    788\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    790\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:206\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m     subprocess.run(cmd, check=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    208\u001b[39m     ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hierarchical_yolo/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:204\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    203\u001b[39m     LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[33m'\u001b[39m\u001b[33mDDP:\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m debug command \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(cmd)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     retcode = process.poll()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['/home/noaa_brown/hierarchical_yolo/.venv/bin/python3', '-m', 'torch.distributed.run', '--nproc_per_node', '7', '--master_port', '60379', '/home/noaa_brown/.config/Ultralytics/DDP/_temp_8to57xks134598790317360.py']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data=YOLO_TRAIN_YAML, \n",
    "    epochs=5, imgsz=640, \n",
    "    device=devices, \n",
    "    batch=max(len(devices), 1),\n",
    "    trainer=Deep7HierarchicalDetectionTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98783e2-d11e-41d1-83c2-a10a12bcf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img = os.path.join(IMAGES_PATH, str(np.random.choice(os.listdir(IMAGES_PATH))))\n",
    "random_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ac518-367d-45a0-928c-84f4f63c59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOCATION = os.path.join('..','runs','detect')\n",
    "trained_models = os.listdir(os.path.join('..','runs','detect'))\n",
    "model_numbers = map(lambda x: int(x[len('train'):]) if len(x) > len('train') else 0, trained_models)\n",
    "latest_model = 'train' + str(max(model_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a45d2a-c07d-4810-bf73-01d7bc0c1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = YOLO(\n",
    "    YOLO_YAML\n",
    ").load(os.path.join(MODEL_LOCATION, latest_model, 'weights', 'best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e0c0a-ff41-4da1-b488-1a8e4aa49dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trained_model.predict(random_img, verbose=False, device=devices[:1], stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466de62-7ec7-47e5-bad6-46d6f8726517",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = next(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1e1b7-ad91-4447-8e90-3ccab5291edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070c873-1928-4c41-be6d-c943a40364af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79949504-3e7a-404c-a85b-2b4ba982e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.save('pickles.jpg')\n",
    "from IPython.display import Image\n",
    "Image(filename='pickles.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfa8ee-ac7b-4b6b-b17b-57b0a1429163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ca8e0-a80b-475a-acd7-b4fe288f0c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932febb-1d7b-4fe3-9785-cc1114de6bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
